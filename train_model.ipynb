{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1d43861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 1182.705980776004\n",
      "Validation RMSE: 31628.393675328505\n",
      "Test Predictions:\n",
      "[120744.86 143629.83 195179.44 ... 154669.16 114810.97 227237.33]\n"
     ]
    }
   ],
   "source": [
    "#perform xgboost model to predic SalePrice......\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "# fUNCTION TO HANDLE OUTLIERS\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# DATASET\n",
    "train_df = pd.read_csv(r'C:\\Users\\nh013\\Desktop\\House Prices - Advanced Regression Techniques dataset\\train.csv')\n",
    "test_df = pd.read_csv(r'C:\\Users\\nh013\\Desktop\\House Prices - Advanced Regression Techniques dataset\\test.csv')\n",
    "\n",
    "\n",
    "\n",
    "# SEPERATE THE TARGET VARIABLE SALES PRICE FROM THE TRAIN DATASET \n",
    "target = train_df['SalePrice']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TRANSFORM NEIGHBORHOOD INTO 0,1,2,3  BASED ON STATISTICS\n",
    "neighborhood_stats = train_df.groupby('Neighborhood')['SalePrice'].median()\n",
    "train_df['Neighborhood'] = train_df['Neighborhood'].map(lambda x: 0 if neighborhood_stats[x] < 150000 else (1 if neighborhood_stats[x] < 200000 else 2))\n",
    "\n",
    "train_df.drop('SalePrice', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# CONCATENATE TRAIN AND TEST  DATAFRAME  FOR PREPROCESS\n",
    "all_data = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# IDENTIFY MISSINFG VALUES\n",
    "missing_values = all_data.isnull().sum()\n",
    "\n",
    "\n",
    "# SELECT_DTYPES() FUNCTION FROM PANDAS  TO  SELECT COLUMNS WITH  SPECIFIC DATA TYPE (INT64,FLOAT64) FROM THE ALL_DATA FRAME\n",
    "#NUMERICAL\n",
    "\n",
    "numeric_features = all_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "\n",
    "\n",
    "#SELECT_DTYPES() FUNCTION FROM PANDAS  TO  SELECT COLUMNS WITH  SPECIFIC DATA TYPE (INT64,FLOAT64) FROM THE ALL_DATA FRAME\n",
    "#CATEGORICAL \n",
    "\n",
    "categorical_features = all_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "\n",
    "\n",
    "# FILL MISSING VALUES FOR NUMERIC FEATURES USING MEAN\n",
    "all_data[numeric_features] = all_data[numeric_features].fillna(all_data[numeric_features].mean())\n",
    "\n",
    "\n",
    "\n",
    "#  FILL MISSING VALUES FOR CATEGORICAL FEATURES USING MODE \n",
    "all_data[categorical_features] = all_data[categorical_features].fillna(all_data[categorical_features].mode().iloc[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# REMOVE DUPLICATES ROWS\n",
    "all_data.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "# FILL MISSING VALUES WITH FORWARD AND BACKWARD FILL\n",
    "all_data.fillna(method='ffill', inplace=True)\n",
    "all_data.fillna(method='bfill', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# HANDLE OUTLIERS IF SALE_PRICE IN NUMERIC CLUMN\n",
    "if 'SalePrice' in numeric_features:\n",
    "    all_data = handle_outliers(all_data, 'SalePrice')\n",
    "\n",
    "    \n",
    "    \n",
    "# LET'S PERFORM FEATURE ENGINEERING  \n",
    "all_data['IsGarage'] = all_data['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['IsFireplace'] = all_data['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['IsPool'] = all_data['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['IsSecondFloor'] = all_data['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['IsOpenPorch'] = all_data['OpenPorchSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['IsWoodDeck'] = all_data['WoodDeckSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['TotalSqrtFeet'] = all_data['GrLivArea'] + all_data['TotalBsmtSF']\n",
    "all_data['TotalBaths'] = all_data['BsmtFullBath'] + all_data['FullBath'] + all_data['BsmtHalfBath']/2 + all_data['HalfBath']/2\n",
    "\n",
    "\n",
    "# ONE HOT ENCODING FOR CATEGORICAL DATA \n",
    "all_data = pd.get_dummies(all_data)\n",
    "\n",
    "\n",
    "# NORMALIZE\n",
    "scaler = StandardScaler()\n",
    "all_data[numeric_features] = scaler.fit_transform(all_data[numeric_features])\n",
    "\n",
    "\n",
    "# SPLIT THE DATA BACK  INTO TRAIN AND TEST DATAFRAME \n",
    "train_df = all_data.iloc[:len(train_df), :]\n",
    "test_df = all_data.iloc[len(train_df):, :]\n",
    "\n",
    "\n",
    "# SPLIT THE TRAIN DATASET INTO TRAIN AND VALIDATION SETS\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_df, target, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# MODELIZATION \n",
    "xgb_model = xgb.XGBRegressor()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICT USING TRAIN MODEL\n",
    "train_predictions = xgb_model.predict(X_train)\n",
    "val_predictions = xgb_model.predict(X_val)\n",
    "\n",
    "\n",
    "# EVALUATE \n",
    "train_rmse = mean_squared_error(y_train, train_predictions, squared=False)\n",
    "val_rmse = mean_squared_error(y_val, val_predictions, squared=False)\n",
    "\n",
    "\n",
    "print(\"Training RMSE:\", train_rmse)\n",
    "print(\"Validation RMSE:\", val_rmse)\n",
    "\n",
    "\n",
    "# PREDICT SELES PRICE FOR THE TEST DATASET \n",
    "test_predictions = xgb_model.predict(test_df)\n",
    "\n",
    "\n",
    "print(\"Test Predictions:\")\n",
    "print(test_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e026bde9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c192035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f2cd525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 773.034880294253\n",
      "Validation RMSE: 29924.101487130258\n",
      "Submission file created successfully.\n"
     ]
    }
   ],
   "source": [
    "#apply GridSearchCV for overfitting reduce and hyperparameter tuning ..........\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "# fUNCTION TO HANDLE OUTLIERS\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DATASET\n",
    "train_df = pd.read_csv(r'C:\\Users\\nh013\\Desktop\\House Prices - Advanced Regression Techniques dataset\\train.csv')\n",
    "test_df = pd.read_csv(r'C:\\Users\\nh013\\Desktop\\House Prices - Advanced Regression Techniques dataset\\test.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# SEPERATE THE TARGET VARIABLE SALES PRICE FROM THE TRAIN DATASET \n",
    "target = train_df['SalePrice']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TRANSFORM NEIGHBORHOOD INTO 0,1,2,3  BASED ON STATISTICS\n",
    "neighborhood_stats = train_df.groupby('Neighborhood')['SalePrice'].median()\n",
    "train_df['Neighborhood'] = train_df['Neighborhood'].map(lambda x: 0 if neighborhood_stats[x] < 150000 else (1 if neighborhood_stats[x] < 200000 else 2))\n",
    "\n",
    "train_df.drop('SalePrice', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# CONCATENATE TRAIN AND TEST  DATAFRAME  FOR PREPROCESS\n",
    "all_data = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# IDENTIFY MISSINFG VALUES\n",
    "missing_values = all_data.isnull().sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# SELECT_DTYPES() FUNCTION FROM PANDAS  TO  SELECT COLUMNS WITH  SPECIFIC DATA TYPE (INT64,FLOAT64) FROM THE ALL_DATA FRAME\n",
    "#NUMERICAL\n",
    "\n",
    "numeric_features = all_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "\n",
    "\n",
    "#SELECT_DTYPES() FUNCTION FROM PANDAS  TO  SELECT COLUMNS WITH  SPECIFIC DATA TYPE (INT64,FLOAT64) FROM THE ALL_DATA FRAME\n",
    "#CATEGORICAL \n",
    "\n",
    "categorical_features = all_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# FILL MISSING VALUES FOR NUMERIC FEATURES USING MEAN\n",
    "all_data[numeric_features] = all_data[numeric_features].fillna(all_data[numeric_features].mean())\n",
    "\n",
    "\n",
    "\n",
    "#  FILL MISSING VALUES FOR CATEGORICAL FEATURES USING MODE \n",
    "all_data[categorical_features] = all_data[categorical_features].fillna(all_data[categorical_features].mode().iloc[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# REMOVE DUPLICATES ROWS\n",
    "all_data.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# FILL MISSING VALUES WITH FORWARD AND BACKWARD FILL\n",
    "all_data.fillna(method='ffill', inplace=True)\n",
    "all_data.fillna(method='bfill', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# HANDLE OUTLIERS IF SALE_PRICE IN NUMERIC CLUMN\n",
    "if 'SalePrice' in numeric_features:\n",
    "    all_data = handle_outliers(all_data, 'SalePrice')\n",
    "\n",
    "    \n",
    "    \n",
    "# LET'S PERFORM FEATURE ENGINEERING  \n",
    "all_data['IsGarage'] = all_data['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['IsFireplace'] = all_data['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['IsPool'] = all_data['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['IsSecondFloor'] = all_data['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['IsOpenPorch'] = all_data['OpenPorchSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['IsWoodDeck'] = all_data['WoodDeckSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['TotalSqrtFeet'] = all_data['GrLivArea'] + all_data['TotalBsmtSF']\n",
    "all_data['TotalBaths'] = all_data['BsmtFullBath'] + all_data['FullBath'] + all_data['BsmtHalfBath']/2 + all_data['HalfBath']/2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ONE HOT ENCODING FOR CATEGORICAL DATA \n",
    "all_data = pd.get_dummies(all_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# NORMALIZE\n",
    "scaler = StandardScaler()\n",
    "all_data[numeric_features] = scaler.fit_transform(all_data[numeric_features])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# SPLIT THE DATA BACK  INTO TRAIN AND TEST DATAFRAME \n",
    "train_df = all_data.iloc[:len(train_df), :]\n",
    "test_df = all_data.iloc[len(train_df):, :]\n",
    "\n",
    "\n",
    "# SPLIT THE TRAIN DATASET INTO TRAIN AND VALIDATION SETS\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_df, target, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# MODEL TRAINING WITH CROSS-VALIDATION\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "params = {\n",
    "    'alpha': [0.1, 0.5, 1.0],\n",
    "    'lambda': [0.1, 0.5, 1.0]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=params, cv=5, scoring='neg_root_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#THE BEST MODEL\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "#PREDICT USING TRAIN MODLE \n",
    "train_predictions = best_model.predict(X_train)\n",
    "val_predictions = best_model.predict(X_val)\n",
    "\n",
    "\n",
    "\n",
    "# EVALUATE \n",
    "train_rmse = mean_squared_error(y_train, train_predictions, squared=False)\n",
    "val_rmse = mean_squared_error(y_val, val_predictions, squared=False)\n",
    "\n",
    "print(\"Training RMSE:\", train_rmse)\n",
    "print(\"Validation RMSE:\", val_rmse)\n",
    "\n",
    "\n",
    "\n",
    "# PREDICT SELES PRICE FOR TEST DATASET \n",
    "test_predictions = best_model.predict(test_df)\n",
    "\n",
    "\n",
    "\n",
    "#RETRIVE ORGINAL ID VALUSE FROM TRAINING DATASET \n",
    "train_ids = train_df['Id']\n",
    "\n",
    "\n",
    "# GENERATE ID VALUSES  FOR THE TEST DATASET  STARTING FROM 1461\n",
    "start_id = 1461\n",
    "test_ids = pd.Series(range(start_id, start_id + len(test_df)))\n",
    "\n",
    "\n",
    "# MAKE SUBMISSION DATAFRAME \n",
    "submission = pd.DataFrame()\n",
    "submission['Id'] = test_ids\n",
    "submission['SalePrice'] = test_predictions\n",
    "\n",
    "\n",
    "\n",
    "# SET ID COL AS THE INDEX FOR SUBMISSION DATAFRAME \n",
    "submission.set_index('Id', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# SAVE SUBMISSION\n",
    "submission.to_csv('submission.csv')\n",
    "\n",
    "print(\"Submission file created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce4da91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c87cdf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58360654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 4595568566.300028\n",
      "R^2 Score: 0.4008639995005737\n",
      "Submission file created successfully.\n"
     ]
    }
   ],
   "source": [
    "#perform linear regression to predict sales price \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# fUNCTION TO HANDLE OUTLIERS\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DATASET\n",
    "train_df = pd.read_csv(r'C:\\Users\\nh013\\Desktop\\House Prices - Advanced Regression Techniques dataset\\train.csv')\n",
    "test_df = pd.read_csv(r'C:\\Users\\nh013\\Desktop\\House Prices - Advanced Regression Techniques dataset\\test.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# SEPERATE THE TARGET VARIABLE SALES PRICE FROM THE TRAIN DATASET \n",
    "target = train_df['SalePrice']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TRANSFORM NEIGHBORHOOD INTO 0,1,2,3  BASED ON STATISTICS\n",
    "neighborhood_stats = train_df.groupby('Neighborhood')['SalePrice'].median()\n",
    "train_df['Neighborhood'] = train_df['Neighborhood'].map(lambda x: 0 if neighborhood_stats[x] < 150000 else (1 if neighborhood_stats[x] < 200000 else 2))\n",
    "\n",
    "train_df.drop('SalePrice', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# CONCATENATE TRAIN AND TEST  DATAFRAME  FOR PREPROCESS\n",
    "all_data = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# IDENTIFY MISSINFG VALUES\n",
    "missing_values = all_data.isnull().sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# SELECT_DTYPES() FUNCTION FROM PANDAS  TO  SELECT COLUMNS WITH  SPECIFIC DATA TYPE (INT64,FLOAT64) FROM THE ALL_DATA FRAME\n",
    "#NUMERICAL\n",
    "\n",
    "numeric_features = all_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "\n",
    "\n",
    "#SELECT_DTYPES() FUNCTION FROM PANDAS  TO  SELECT COLUMNS WITH  SPECIFIC DATA TYPE (INT64,FLOAT64) FROM THE ALL_DATA FRAME\n",
    "#CATEGORICAL \n",
    "\n",
    "categorical_features = all_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# FILL MISSING VALUES FOR NUMERIC FEATURES USING MEAN\n",
    "all_data[numeric_features] = all_data[numeric_features].fillna(all_data[numeric_features].mean())\n",
    "\n",
    "\n",
    "\n",
    "#  FILL MISSING VALUES FOR CATEGORICAL FEATURES USING MODE \n",
    "all_data[categorical_features] = all_data[categorical_features].fillna(all_data[categorical_features].mode().iloc[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# REMOVE DUPLICATES ROWS\n",
    "all_data.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# FILL MISSING VALUES WITH FORWARD AND BACKWARD FILL\n",
    "all_data.fillna(method='ffill', inplace=True)\n",
    "all_data.fillna(method='bfill', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# HANDLE OUTLIERS IF SALE_PRICE IN NUMERIC CLUMN\n",
    "if 'SalePrice' in numeric_features:\n",
    "    all_data = handle_outliers(all_data, 'SalePrice')\n",
    "\n",
    "    \n",
    "    \n",
    "# LET'S PERFORM FEATURE ENGINEERING  \n",
    "all_data['IsGarage'] = all_data['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['IsFireplace'] = all_data['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['IsPool'] = all_data['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['IsSecondFloor'] = all_data['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['IsOpenPorch'] = all_data['OpenPorchSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['IsWoodDeck'] = all_data['WoodDeckSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['TotalSqrtFeet'] = all_data['GrLivArea'] + all_data['TotalBsmtSF']\n",
    "all_data['TotalBaths'] = all_data['BsmtFullBath'] + all_data['FullBath'] + all_data['BsmtHalfBath']/2 + all_data['HalfBath']/2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ONE HOT ENCODING FOR CATEGORICAL DATA \n",
    "all_data = pd.get_dummies(all_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# NORMALIZE\n",
    "scaler = StandardScaler()\n",
    "all_data[numeric_features] = scaler.fit_transform(all_data[numeric_features])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# SPLIT THE DATA BACK  INTO TRAIN AND TEST DATAFRAME \n",
    "train_df = all_data.iloc[:len(train_df), :]\n",
    "test_df = all_data.iloc[len(train_df):, :]\n",
    "\n",
    "\n",
    "# SPLIT THE TRAIN AND TEST DATASET \n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df, target, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# MODELIZATION\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICT ON TEST SET\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# EVALUATE \n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('Mean Squared Error:', mse)\n",
    "print('R^2 Score:', r2)\n",
    "\n",
    "\n",
    "# PREDICT THE SALE PRICE FOR TEST SET\n",
    "test_predictions = model.predict(test_df)\n",
    "\n",
    "# MAKE SUBMISSION DATFRAME \n",
    "submission = pd.DataFrame()\n",
    "submission['Id'] = range(1461, 1461 + len(test_df))\n",
    "submission['SalePrice'] = test_predictions\n",
    "\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e102d4cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c90533c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60049256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1000883098.3437394\n",
      "R^2 Score: 0.8695123165158337\n",
      "Submission file created successfully.\n"
     ]
    }
   ],
   "source": [
    "#Ridge regression is used instead of Linear regression to reduce overfitting\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# fUNCTION TO HANDLE OUTLIERS\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DATASET\n",
    "train_df = pd.read_csv(r'C:\\Users\\nh013\\Desktop\\House Prices - Advanced Regression Techniques dataset\\train.csv')\n",
    "test_df = pd.read_csv(r'C:\\Users\\nh013\\Desktop\\House Prices - Advanced Regression Techniques dataset\\test.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# SEPERATE THE TARGET VARIABLE SALES PRICE FROM THE TRAIN DATASET \n",
    "target = train_df['SalePrice']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TRANSFORM NEIGHBORHOOD INTO 0,1,2,3  BASED ON STATISTICS\n",
    "neighborhood_stats = train_df.groupby('Neighborhood')['SalePrice'].median()\n",
    "train_df['Neighborhood'] = train_df['Neighborhood'].map(lambda x: 0 if neighborhood_stats[x] < 150000 else (1 if neighborhood_stats[x] < 200000 else 2))\n",
    "\n",
    "train_df.drop('SalePrice', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# CONCATENATE TRAIN AND TEST  DATAFRAME  FOR PREPROCESS\n",
    "all_data = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# IDENTIFY MISSINFG VALUES\n",
    "missing_values = all_data.isnull().sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# SELECT_DTYPES() FUNCTION FROM PANDAS  TO  SELECT COLUMNS WITH  SPECIFIC DATA TYPE (INT64,FLOAT64) FROM THE ALL_DATA FRAME\n",
    "#NUMERICAL\n",
    "\n",
    "numeric_features = all_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "\n",
    "\n",
    "#SELECT_DTYPES() FUNCTION FROM PANDAS  TO  SELECT COLUMNS WITH  SPECIFIC DATA TYPE (INT64,FLOAT64) FROM THE ALL_DATA FRAME\n",
    "#CATEGORICAL \n",
    "\n",
    "categorical_features = all_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# FILL MISSING VALUES FOR NUMERIC FEATURES USING MEAN\n",
    "all_data[numeric_features] = all_data[numeric_features].fillna(all_data[numeric_features].mean())\n",
    "\n",
    "\n",
    "\n",
    "#  FILL MISSING VALUES FOR CATEGORICAL FEATURES USING MODE \n",
    "all_data[categorical_features] = all_data[categorical_features].fillna(all_data[categorical_features].mode().iloc[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# REMOVE DUPLICATES ROWS\n",
    "all_data.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# FILL MISSING VALUES WITH FORWARD AND BACKWARD FILL\n",
    "all_data.fillna(method='ffill', inplace=True)\n",
    "all_data.fillna(method='bfill', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# HANDLE OUTLIERS IF SALE_PRICE IN NUMERIC CLUMN\n",
    "if 'SalePrice' in numeric_features:\n",
    "    all_data = handle_outliers(all_data, 'SalePrice')\n",
    "\n",
    "    \n",
    "    \n",
    "# LET'S PERFORM FEATURE ENGINEERING  \n",
    "all_data['IsGarage'] = all_data['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['IsFireplace'] = all_data['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['IsPool'] = all_data['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['IsSecondFloor'] = all_data['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['IsOpenPorch'] = all_data['OpenPorchSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['IsWoodDeck'] = all_data['WoodDeckSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['TotalSqrtFeet'] = all_data['GrLivArea'] + all_data['TotalBsmtSF']\n",
    "all_data['TotalBaths'] = all_data['BsmtFullBath'] + all_data['FullBath'] + all_data['BsmtHalfBath']/2 + all_data['HalfBath']/2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ONE HOT ENCODING FOR CATEGORICAL DATA \n",
    "all_data = pd.get_dummies(all_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# NORMALIZE\n",
    "scaler = StandardScaler()\n",
    "all_data[numeric_features] = scaler.fit_transform(all_data[numeric_features])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# SPLIT THE DATA BACK  INTO TRAIN AND TEST DATAFRAME \n",
    "train_df = all_data.iloc[:len(train_df), :]\n",
    "test_df = all_data.iloc[len(train_df):, :]\n",
    "\n",
    "\n",
    "\n",
    "# SPLIT TRAN AND TEST SET \n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df, target, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# MAKE AND TRAIN RIDGES REGRESSION MODEL WITH THE HYPERPAREMETER TUNING\n",
    "params = {'alpha': [0.01, 0.1, 1.0, 10.0]}\n",
    "ridge = Ridge()\n",
    "grid_search = GridSearchCV(ridge, params, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "\n",
    "# TRAIN MODEL WITH THE BEST ALPHA \n",
    "model = Ridge(alpha=best_alpha)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# PREDICT ON TEST SET \n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# EVALUATE \n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('Mean Squared Error:', mse)\n",
    "print('R^2 Score:', r2)\n",
    "\n",
    "# PREDICT THE SALES PRICE FOR THE TEST DATFRAME \n",
    "test_predictions = model.predict(test_df)\n",
    "\n",
    "\n",
    "# MAKE SUBMISSION DATFRAME \n",
    "submission = pd.DataFrame()\n",
    "submission['Id'] = range(1461, 1461 + len(test_df))\n",
    "submission['SalePrice'] = test_predictions\n",
    "\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcd8d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32e5fe27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 722475960.4532174\n",
      "R^2 Score: 0.9058089654940289\n",
      "Submission file created successfully.\n"
     ]
    }
   ],
   "source": [
    "#perform gredient boosting regressor model ....to predict sales price \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Function to handle outliers\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "\n",
    "# DATASET\n",
    "train_df = pd.read_csv(r'C:\\Users\\nh013\\Desktop\\House Prices - Advanced Regression Techniques dataset\\train.csv')\n",
    "test_df = pd.read_csv(r'C:\\Users\\nh013\\Desktop\\House Prices - Advanced Regression Techniques dataset\\test.csv')\n",
    "\n",
    "# SEPARATE THE TARGET VARIABLE 'SalePrice' FROM THE TRAIN DATASET\n",
    "target = train_df['SalePrice']\n",
    "\n",
    "# TRANSFORM 'Neighborhood' INTO 0, 1, 2, 3 BASED ON STATISTICS\n",
    "neighborhood_stats = train_df.groupby('Neighborhood')['SalePrice'].median()\n",
    "train_df['Neighborhood'] = train_df['Neighborhood'].map(lambda x: 0 if neighborhood_stats[x] < 150000 else (1 if neighborhood_stats[x] < 200000 else 2))\n",
    "\n",
    "train_df.drop('SalePrice', axis=1, inplace=True)\n",
    "\n",
    "# CONCATENATE TRAIN AND TEST DATAFRAMES FOR PREPROCESSING\n",
    "all_data = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "# IDENTIFY MISSING VALUES\n",
    "missing_values = all_data.isnull().sum()\n",
    "\n",
    "# SELECT COLUMNS WITH SPECIFIC DATA TYPES (int64, float64) FROM THE ALL_DATA DATAFRAME (NUMERIC)\n",
    "numeric_features = all_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# SELECT COLUMNS WITH SPECIFIC DATA TYPES (object) FROM THE ALL_DATA DATAFRAME (CATEGORICAL)\n",
    "categorical_features = all_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# FILL MISSING VALUES FOR NUMERIC FEATURES USING MEAN\n",
    "all_data[numeric_features] = all_data[numeric_features].fillna(all_data[numeric_features].mean())\n",
    "\n",
    "# FILL MISSING VALUES FOR CATEGORICAL FEATURES USING MODE\n",
    "all_data[categorical_features] = all_data[categorical_features].fillna(all_data[categorical_features].mode().iloc[0])\n",
    "\n",
    "# REMOVE DUPLICATE ROWS\n",
    "all_data.drop_duplicates(inplace=True)\n",
    "\n",
    "# FILL MISSING VALUES WITH FORWARD AND BACKWARD FILL\n",
    "all_data.fillna(method='ffill', inplace=True)\n",
    "all_data.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# HANDLE OUTLIERS IF 'SalePrice' IS IN NUMERIC FEATURES\n",
    "if 'SalePrice' in numeric_features:\n",
    "    all_data = handle_outliers(all_data, 'SalePrice')\n",
    "\n",
    "# FEATURE ENGINEERING\n",
    "all_data['IsGarage'] = all_data['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['IsFireplace'] = all_data['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['IsPool'] = all_data['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['IsSecondFloor'] = all_data['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['IsOpenPorch'] = all_data['OpenPorchSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['IsWoodDeck'] = all_data['WoodDeckSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['TotalSqrtFeet'] = all_data['GrLivArea'] + all_data['TotalBsmtSF']\n",
    "all_data['TotalBaths'] = all_data['BsmtFullBath'] + all_data['FullBath'] + all_data['BsmtHalfBath'] / 2 + all_data['HalfBath'] / 2\n",
    "\n",
    "# ONE-HOT ENCODING FOR CATEGORICAL DATA\n",
    "all_data = pd.get_dummies(all_data)\n",
    "\n",
    "# NORMALIZE\n",
    "scaler = StandardScaler()\n",
    "all_data[numeric_features] = scaler.fit_transform(all_data[numeric_features])\n",
    "\n",
    "# SPLIT THE DATA BACK INTO TRAIN AND TEST DATAFRAMES\n",
    "train_df = all_data.iloc[:len(train_df), :]\n",
    "test_df = all_data.iloc[len(train_df):, :]\n",
    "\n",
    "# PREPARE TRAIN AND TEST SETS\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# GRADIENT BOOSTING REGRESSOR\n",
    "params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.1, 0.05, 0.01],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "gb_regressor = GradientBoostingRegressor()\n",
    "\n",
    "# GRID SEARCH FOR HYPERPARAMETER TUNING\n",
    "grid_search = GridSearchCV(gb_regressor, params, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# BEST ESTIMATOR\n",
    "best_gb_regressor = grid_search.best_estimator_\n",
    "\n",
    "# PREDICT ON THE TEST SET\n",
    "y_pred = best_gb_regressor.predict(X_test)\n",
    "\n",
    "# EVALUATE THE MODEL\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('Mean Squared Error:', mse)\n",
    "print('R^2 Score:', r2)\n",
    "\n",
    "# PREDICT THE SALE PRICES FOR THE TEST DATASET\n",
    "test_predictions = best_gb_regressor.predict(test_df)\n",
    "\n",
    "# CREATE SUBMISSION DATAFRAME\n",
    "submission = pd.DataFrame()\n",
    "submission['Id'] = range(1461, 1461 + len(test_df))\n",
    "submission['SalePrice'] = test_predictions\n",
    "\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a46d18d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
